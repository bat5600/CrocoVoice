# Epic 13 â€” Local VAD/ASR Path

## Status
Draft

## Story
**As a** privacy-focused user,
**I want** an optional local VAD/ASR path,
**so that** dictation can continue even when cloud services are unavailable.

## Acceptance Criteria
1. Local inference can be enabled when supported hardware is detected (or when a local model is present).
2. Local VAD/ASR can process short dictations end-to-end without cloud calls.
3. Local inference is gated by a feature flag and can be disabled safely.
4. Local inference output flows through the same dictionary/personalization pipeline as cloud output.

## Tasks / Subtasks
- [ ] Integrate ONNX runtime or local ASR/VAD engine (AC: 1,2)
- [ ] Add local model discovery + capability checks (AC: 1,3)
- [ ] Wire local inference into the pipeline (AC: 2,4)
- [ ] Add feature flag gating and safe disable behavior (AC: 3)

## Dev Notes
- Keep this feature optional and gated by a feature flag.
- Avoid shipping large models unless explicitly configured.

### Testing
- Manual: enable local inference, verify dictation completes without cloud calls.

## Change Log
| Date | Version | Description | Author |
| --- | --- | --- | --- |
| 2026-01-24 | v0.1 | New epic for local inference fallback | PO |

## Dev Agent Record
### Agent Model Used
TBD

### Debug Log References
N/A

### Completion Notes List
- TBD

### File List
- TBD

## QA Results
